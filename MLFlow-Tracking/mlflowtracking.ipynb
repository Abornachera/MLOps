{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51a4f30",
   "metadata": {},
   "source": [
    "# Dataset QSAR Biodegradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bc1961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919</td>\n",
       "      <td>2.6909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949</td>\n",
       "      <td>1.591</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170</td>\n",
       "      <td>2.1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.315</td>\n",
       "      <td>1.967</td>\n",
       "      <td>0</td>\n",
       "      <td>7.257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932</td>\n",
       "      <td>3.2512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.417</td>\n",
       "      <td>0</td>\n",
       "      <td>7.601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.7098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.046</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236</td>\n",
       "      <td>3.3944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0</td>\n",
       "      <td>8.003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.236</td>\n",
       "      <td>3.4286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.556</td>\n",
       "      <td>0</td>\n",
       "      <td>7.904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.000</td>\n",
       "      <td>5.0476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.712</td>\n",
       "      <td>4.583</td>\n",
       "      <td>0</td>\n",
       "      <td>9.303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.525</td>\n",
       "      <td>3.8301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.143</td>\n",
       "      <td>0</td>\n",
       "      <td>7.950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.596</td>\n",
       "      <td>3.0777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.626</td>\n",
       "      <td>1.917</td>\n",
       "      <td>0</td>\n",
       "      <td>7.939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.040</td>\n",
       "      <td>3.6112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.888</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1</td>\n",
       "      <td>8.706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1      V2  V3  V4  V5  V6  V7    V8  V9  V10  ...  V33  V34  V35  \\\n",
       "0  3.919  2.6909   0   0   0   0   0  31.4   2    0  ...    0    0    0   \n",
       "1  4.170  2.1144   0   0   0   0   0  30.8   1    1  ...    0    0    0   \n",
       "2  3.932  3.2512   0   0   0   0   0  26.7   2    4  ...    0    0    1   \n",
       "3  3.000  2.7098   0   0   0   0   0  20.0   0    2  ...    0    0    1   \n",
       "4  4.236  3.3944   0   0   0   0   0  29.4   2    4  ...    0    0    0   \n",
       "5  4.236  3.4286   0   0   0   0   0  28.6   2    4  ...    0    0    0   \n",
       "6  5.000  5.0476   1   0   0   0   0  11.1   0    3  ...    0    0    1   \n",
       "7  4.525  3.8301   0   0   0   0   0  31.6   3    2  ...    0    0    0   \n",
       "8  4.596  3.0777   0   0   0   0   2  44.4   2    0  ...    0    0    0   \n",
       "9  5.040  3.6112   0   0   1   0   2  41.2   0    4  ...    1    2    1   \n",
       "\n",
       "     V36    V37  V38    V39  V40  V41  Class  \n",
       "0  2.949  1.591    0  7.253    0    0      2  \n",
       "1  3.315  1.967    0  7.257    0    0      2  \n",
       "2  3.076  2.417    0  7.601    0    0      2  \n",
       "3  3.046  5.000    0  6.690    0    0      2  \n",
       "4  3.351  2.405    0  8.003    0    0      2  \n",
       "5  3.351  2.556    0  7.904    0    0      2  \n",
       "6  4.712  4.583    0  9.303    0    0      2  \n",
       "7  3.379  2.143    0  7.950    0    0      2  \n",
       "8  3.626  1.917    0  7.939    0    0      2  \n",
       "9  3.888  3.500    1  8.706    0    0      2  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('/Users/anderson/Desktop/proyectos GIT/MLOps/MLFlow-Tracking/qsar-biodeg.csv')\n",
    "\n",
    "df.head(10)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff0948",
   "metadata": {},
   "source": [
    "## Convertir la columna class en binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38368f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Valores Ãºnicos en 'Class' antes de convertir:\n",
      "[2 1]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 42 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      1055 non-null   float64\n",
      " 1   V2      1055 non-null   float64\n",
      " 2   V3      1055 non-null   int64  \n",
      " 3   V4      1055 non-null   int64  \n",
      " 4   V5      1055 non-null   int64  \n",
      " 5   V6      1055 non-null   int64  \n",
      " 6   V7      1055 non-null   int64  \n",
      " 7   V8      1055 non-null   float64\n",
      " 8   V9      1055 non-null   int64  \n",
      " 9   V10     1055 non-null   int64  \n",
      " 10  V11     1055 non-null   int64  \n",
      " 11  V12     1055 non-null   float64\n",
      " 12  V13     1055 non-null   float64\n",
      " 13  V14     1055 non-null   float64\n",
      " 14  V15     1055 non-null   float64\n",
      " 15  V16     1055 non-null   int64  \n",
      " 16  V17     1055 non-null   float64\n",
      " 17  V18     1055 non-null   float64\n",
      " 18  V19     1055 non-null   int64  \n",
      " 19  V20     1055 non-null   int64  \n",
      " 20  V21     1055 non-null   int64  \n",
      " 21  V22     1055 non-null   float64\n",
      " 22  V23     1055 non-null   int64  \n",
      " 23  V24     1055 non-null   int64  \n",
      " 24  V25     1055 non-null   int64  \n",
      " 25  V26     1055 non-null   int64  \n",
      " 26  V27     1055 non-null   float64\n",
      " 27  V28     1055 non-null   float64\n",
      " 28  V29     1055 non-null   int64  \n",
      " 29  V30     1055 non-null   float64\n",
      " 30  V31     1055 non-null   float64\n",
      " 31  V32     1055 non-null   int64  \n",
      " 32  V33     1055 non-null   int64  \n",
      " 33  V34     1055 non-null   int64  \n",
      " 34  V35     1055 non-null   int64  \n",
      " 35  V36     1055 non-null   float64\n",
      " 36  V37     1055 non-null   float64\n",
      " 37  V38     1055 non-null   int64  \n",
      " 38  V39     1055 non-null   float64\n",
      " 39  V40     1055 non-null   int64  \n",
      " 40  V41     1055 non-null   int64  \n",
      " 41  Class   1055 non-null   int64  \n",
      "dtypes: float64(17), int64(25)\n",
      "memory usage: 346.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Asegurarse de que no haya valores nulos en la columna Class\n",
    "df = df.dropna(subset=['Class'])\n",
    "\n",
    "# Mostrar los valores Ãºnicos antes de la conversiÃ³n\n",
    "print(\"ğŸ”¹ Valores Ãºnicos en 'Class' antes de convertir:\")\n",
    "print(df['Class'].unique())\n",
    "\n",
    "# Si los valores estÃ¡n como texto, convertirlos a enteros\n",
    "df['Class'] = df['Class'].astype(int)\n",
    "\n",
    "# Convertir la columna a binaria (1 y 0)\n",
    "# Si tu dataset usa 1 y 2 como clases:\n",
    "df['Class'] = df['Class'].map({1: 1, 2: 0})\n",
    "\n",
    "# Si existen otros valores, puedes forzar binarizaciÃ³n con:\n",
    "# df['Class'] = df['Class'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# Verificar si quedaron valores NaN despuÃ©s del mapeo\n",
    "if df['Class'].isna().any():\n",
    "    print(\"\\nâš ï¸ AtenciÃ³n: Se encontraron valores no mapeados. SerÃ¡n reemplazados por 0.\")\n",
    "    df['Class'] = df['Class'].fillna(0).astype(int)\n",
    "\n",
    "# Mostrar resultados despuÃ©s de la conversiÃ³n\n",
    "df.info(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f8363",
   "metadata": {},
   "source": [
    "## DivisiÃ³n de datos de entrenamiento y datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f396f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98036e36",
   "metadata": {},
   "source": [
    "## EstandarizaciÃ³n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461f389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos el scaler SÃ“LO con los datos de entrenamiento\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicamos la transformaciÃ³n a los datos de prueba\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba3f94",
   "metadata": {},
   "source": [
    "## CreaciÃ³n del experimento en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c815df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/anderson/Desktop/proyectos%20GIT/MLOps/MLFlow-Tracking/mlruns/354037731558514546', creation_time=1762297336647, experiment_id='354037731558514546', last_update_time=1762297336647, lifecycle_stage='active', name='QSAR_Biodegradation_Experiment', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"QSAR_Biodegradation_Experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053dd25",
   "metadata": {},
   "source": [
    "##  RegresiÃ³n LogÃ­stica (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb7a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.8436\n",
      "  F1-Score: 0.8842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR_Manual_v1\"):\n",
    "\n",
    "    params = {\n",
    "        \"C\": 0.5,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"max_iter\": 150\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Metadatos\n",
    "    tags = {\n",
    "        \"model_type\": \"Scikit-learn Logistic Regression\",\n",
    "        \"logging_type\": \"Manual\",\n",
    "        \"purpose\": \"Baseline Model\"\n",
    "    }\n",
    "    mlflow.set_tags(tags)\n",
    "\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        C=params[\"C\"],\n",
    "        solver=params[\"solver\"],\n",
    "        max_iter=params[\"max_iter\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # EvaluaciÃ³n de mÃ©tricas\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    # Calculo de mÃ©tricas\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Registrar las mÃ©tricas\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  F1-Score: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "    # GrÃ¡ficos y Archivos\n",
    "\n",
    "    # a) Guardar una nota de texto\n",
    "    mlflow.log_text(\"Modelo base de RegresiÃ³n LogÃ­stica.\", \n",
    "                   artifact_file=\"description.txt\")\n",
    "\n",
    "    # b) Guardar un grÃ¡fico (Matriz de ConfusiÃ³n)\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, cmap='Blues')\n",
    "    plt.title(\"Matriz de ConfusiÃ³n (LR)\")\n",
    "    \n",
    "    # Guardamos la figura temporalmente para loggearla\n",
    "    plot_path = \"lr_confusion_matrix.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close(fig) # Cerramos la figura\n",
    "\n",
    "    # Registramos el archivo como artefacto en una subcarpeta \"plots\"\n",
    "    mlflow.log_artifact(plot_path, artifact_path=\"plots\")\n",
    "    \n",
    "    # (Opcional) Borramos el archivo local\n",
    "    os.remove(plot_path)\n",
    "\n",
    "# print(\"Run de RegresiÃ³n LogÃ­stica completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d38ca1a",
   "metadata": {},
   "source": [
    "## Red Neuronal (TensorFlow/Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa003202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anderson/Desktop/proyectos GIT/MLOps/MLFlow-Tracking/MLFlowTracking/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m1,344\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m528\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889</span> (7.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,889\u001b[0m (7.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889</span> (7.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,889\u001b[0m (7.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:14:04 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando entrenamiento de la Red Neuronal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m16/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5557 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7382 - loss: 0.5343 - val_accuracy: 0.7820 - val_loss: 0.4826\n",
      "Epoch 2/20\n",
      "\u001b[1m18/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4983 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8057 - loss: 0.4601 - val_accuracy: 0.8199 - val_loss: 0.4370\n",
      "Epoch 3/20\n",
      "\u001b[1m22/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.4029 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8282 - loss: 0.4094 - val_accuracy: 0.8341 - val_loss: 0.4164\n",
      "Epoch 4/20\n",
      "\u001b[1m18/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.4177 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.3775 - val_accuracy: 0.8341 - val_loss: 0.4006\n",
      "Epoch 5/20\n",
      "\u001b[1m16/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.3871 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8412 - loss: 0.3672 - val_accuracy: 0.8341 - val_loss: 0.3913\n",
      "Epoch 6/20\n",
      "\u001b[1m20/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3957 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8519 - loss: 0.3526 - val_accuracy: 0.8436 - val_loss: 0.3888\n",
      "Epoch 7/20\n",
      "\u001b[1m20/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3725 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8697 - loss: 0.3411 - val_accuracy: 0.8389 - val_loss: 0.3826\n",
      "Epoch 8/20\n",
      "\u001b[1m19/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3344 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8649 - loss: 0.3364 - val_accuracy: 0.8578 - val_loss: 0.3717\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8780 - loss: 0.3097 - val_accuracy: 0.8531 - val_loss: 0.3775\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8697 - loss: 0.3199 - val_accuracy: 0.8578 - val_loss: 0.3776\n",
      "Epoch 11/20\n",
      "\u001b[1m19/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.3119 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8768 - loss: 0.3117 - val_accuracy: 0.8531 - val_loss: 0.3677\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 0.2994 - val_accuracy: 0.8483 - val_loss: 0.3701\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8720 - loss: 0.2975 - val_accuracy: 0.8483 - val_loss: 0.3755\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8827 - loss: 0.3019 - val_accuracy: 0.8483 - val_loss: 0.3712\n",
      "Epoch 15/20\n",
      "\u001b[1m21/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2874 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.2911 - val_accuracy: 0.8531 - val_loss: 0.3643\n",
      "Epoch 16/20\n",
      "\u001b[1m19/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2638 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8957 - loss: 0.2657 - val_accuracy: 0.8531 - val_loss: 0.3640\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8934 - loss: 0.2762 - val_accuracy: 0.8531 - val_loss: 0.3660\n",
      "Epoch 18/20\n",
      "\u001b[1m18/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3046 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8957 - loss: 0.2709 - val_accuracy: 0.8626 - val_loss: 0.3627\n",
      "Epoch 19/20\n",
      "\u001b[1m20/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2715 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8934 - loss: 0.2685 - val_accuracy: 0.8578 - val_loss: 0.3584\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8945 - loss: 0.2631 - val_accuracy: 0.8483 - val_loss: 0.3689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:14:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# SegÃºn la documentaciÃ³n de MLflow, se debe activar el autologging ANTES de definir/compilar/entrenar el modelo\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "# Autologging registrarÃ¡ todo DENTRO de este run\n",
    "with mlflow.start_run(run_name=\"NN_TensorFlow_Autolog_v1\"):\n",
    "\n",
    "    # ParÃ¡metros, Autologging los detectarÃ¡ del model.fit() y model.compile()\n",
    "    epochs = 20\n",
    "    batch_size = 32\n",
    "    optimizer = 'adam'\n",
    "\n",
    "    # (Obtener la dimensionalidad de entrada)\n",
    "    input_dim = X_train_scaled.shape[1] \n",
    "    \n",
    "    # Crear la Red Neuronal con Keras\n",
    "    model = Sequential([\n",
    "        # Primera capa oculta con 32 neuronas\n",
    "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.2), # Esto es para la regularizaciÃ³n\n",
    "        Dense(16, activation='relu'),\n",
    "        # 1 neurona con 'sigmoid' para clasificaciÃ³n binaria\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    # (Autologging registrarÃ¡ 'optimizer', 'loss' y 'metrics')\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Imprimimos un resumen que tambiÃ©n serÃ¡ guardado como artefacto\n",
    "    model.summary()\n",
    "    print(\"\\nIniciando entrenamiento de la Red Neuronal\")\n",
    "\n",
    "    # (Autologging registrarÃ¡ mÃ©tricas por Ã©poca y los resultados finales)\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        # Usamos los datos de test como validaciÃ³n\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=1 # Muestra el progreso\n",
    "    )\n",
    "\n",
    "# print(\"Entrenamiento completado.\")\n",
    "# print(\"El autologging ha registrado todos los resultados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e34c28",
   "metadata": {},
   "source": [
    "## Registrar la InterpretaciÃ³n de Ollama en MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c564941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterpretaciÃ³n guardada como artefacto en MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"Analisis_Ollama\"):\n",
    "    \n",
    "    mlflow.set_tag(\"purpose\", \"Interpretation\")\n",
    "    \n",
    "    # Registramos el archivo de texto como artefacto\n",
    "    mlflow.log_artifact(\"interpretacion_ollama.txt\", artifact_path=\"analysis\")\n",
    "\n",
    "print(\"InterpretaciÃ³n guardada como artefacto en MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf5c82",
   "metadata": {},
   "source": [
    "## Runs Anidados y Autologging Combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb10f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:58:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/11/06 12:58:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/11/06 12:58:58 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se divide en 2 partes: Parte A (Logistic Regression) y Parte B (Red Neuronal)\n",
      "\n",
      "Parte A: BÃºsqueda Anidada (Scikit-learn)\n",
      "Iniciando Run Padre: 381b4304149f43f2821c9989ba7db0d2\n",
      "  Iniciando Run Hijo (C=0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:58:59 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iniciando Run Hijo (C=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:59:00 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iniciando Run Hijo (C=1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/06 12:59:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iniciando Run Hijo (C=5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anderson/Desktop/proyectos GIT/MLOps/MLFlow-Tracking/MLFlowTracking/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/11/06 12:59:02 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado LR: C=5.0 con F1-Score=0.8982\n",
      "--- Parte A Completada ---\n",
      "\n",
      "Parte B: Run de Red Neuronal (TensorFlow)\n",
      "Iniciando Run de Red Neuronal...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Parte B Completada ---\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Esta Ãºnica lÃ­nea activarÃ¡ el autologging para scikit-learn Y tensorflow\n",
    "mlflow.autolog(log_models=False) # (log_models=False para que sea mÃ¡s rÃ¡pido)\n",
    "\n",
    "print(\"Se divide en 2 partes: Parte A (Logistic Regression) y Parte B (Red Neuronal)\")\n",
    "\n",
    "# --- Parte A: BÃºsqueda Anidada con Scikit-learn ---\n",
    "print(\"\\nParte A: BÃºsqueda Anidada (Scikit-learn)\")\n",
    "\n",
    "parameters_to_try = [0.1, 0.5, 1.0, 5.0]\n",
    "\n",
    "# Iniciamos el Run Padre.\n",
    "with mlflow.start_run(run_name=\"LR_Hyperparameter_Search\") as parent_run:\n",
    "    \n",
    "    mlflow.set_tag(\"purpose\", \"Nested Runs Example\")\n",
    "    print(f\"Iniciando Run Padre: {parent_run.info.run_id}\")\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_c = None\n",
    "\n",
    "    # Iterar y crear \"Runs Hijos\"\n",
    "    for c_value in parameters_to_try:\n",
    "        with mlflow.start_run(run_name=f\"LR_C_value_{c_value}\", nested=True) as child_run:\n",
    "            print(f\"  Iniciando Run Hijo (C={c_value})\")\n",
    "            \n",
    "            lr = LogisticRegression(C=c_value, solver='liblinear', random_state=42)\n",
    "            lr.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            y_pred = lr.predict(X_test_scaled)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            # (Autologging ya registra esto, pero lo usamos para nuestra lÃ³gica)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_c = c_value\n",
    "\n",
    "    # Volvemos al Run Padre\n",
    "    print(f\"Mejor resultado LR: C={best_c} con F1-Score={best_f1:.4f}\")\n",
    "    mlflow.log_param(\"best_C\", best_c)\n",
    "    mlflow.log_metric(\"best_f1_score\", best_f1)\n",
    "\n",
    "print(\"--- Parte A Completada ---\")\n",
    "\n",
    "# --- Parte B: Run de Red Neuronal (TensorFlow) ---\n",
    "print(\"\\nParte B: Run de Red Neuronal (TensorFlow)\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN_TensorFlow_Autolog_v2\"):\n",
    "    \n",
    "    mlflow.set_tag(\"purpose\", \"Combined Autolog Example\")\n",
    "    print(\"Iniciando Run de Red Neuronal...\")\n",
    "\n",
    "    # Definir HiperparÃ¡metros\n",
    "    epochs = 15 # Reducimos Ã©pocas para que sea mÃ¡s rÃ¡pido\n",
    "    batch_size = 32\n",
    "    input_dim = X_train_scaled.shape[1] \n",
    "    \n",
    "    # Crear la Red Neuronal\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    # Compilar\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0 # Lo ponemos en 0 para no saturar la consola\n",
    "    )\n",
    "    \n",
    "    print(\"--- Parte B Completada ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLFlowTracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
