
# Taller MLOps: MLflow Tracking, TensorFlow y Ollama

##  Autores

* Anderson Bornachera
* Juan Mosquera


Este repositorio documenta un taller integral de MLOps centrado en el seguimiento de experimentos. El objetivo es aprender a rastrear, comparar y gestionar modelos de Machine Learning utilizando MLflow y, finalmente, interpretar los resultados con un LLM local a trav茅s de Ollama.

## О Herramientas Utilizadas

* **MLflow**: Para el seguimiento de experimentos (Tracking).
* **Scikit-learn**: Para el modelo base (Regresi贸n Log铆stica).
* **TensorFlow/Keras**: Para el modelo de Deep Learning (Red Neuronal).
* **Ollama**: Para la interpretaci贸n de resultados con un LLM local (`tinyllama`).
* **Pandas & Numpy**: Para la manipulaci贸n y preprocesamiento de datos.
* **Jupyter Notebook**: Como entorno de desarrollo interactivo.

##  驴C贸mo Empezar desde Cero?

Sigue estos pasos para configurar y ejecutar el proyecto en un nuevo entorno.

### 1. Prerrequisitos

* [Python 3.9+](https://www.python.org/downloads/)
* [Git](https://www.google.com/search?q=https://git-scm.com/downloads&authuser=2)

### 2. Clonar el Repositorio

```
git clone git@github.com:Abornachera/MLOps.git
cd MlFlow-Tracking/
```

### 3. Configurar el Entorno Virtual

Usaremos la carpeta `MLFlowTracking` como nuestro entorno virtual.

```
# Crear el entorno virtual
python3 -m venv MLFlowTracking

# Activar el entorno (macOS/Linux)
source MLFlowTracking/bin/activate
```

### 4. Instalar Dependencias

```
# Instalar todas las librer铆as necesarias
pip install -r requirements.txt
```

### 5. Iniciar la Interfaz de MLflow

En tu terminal, ejecuta el servidor de MLflow. Este comando crear谩 una carpeta llamada `mlruns`.

```
mlflow ui --port 5000
```

Abre tu navegador y ve a `http://127.0.0.1:5000` para ver la interfaz.


##  Resumen del Taller (Paso a Paso)

Este es un resumen de lo que se construy贸 en el notebook `mlflowtracking.ipynb`.

### Paso 1 & 2: Carga y Preparaci贸n de Datos

* Se carg贸 el dataset `qsar-biodeg.csv` con Pandas.
* La variable objetivo `class` se convirti贸 a formato binario (0/1).
* Los datos se dividieron en `X_train`, `X_test`, `y_train`, `y_test`.
* Se aplic贸 `StandardScaler` a las *features* para normalizar los datos.

### Paso 3: Creaci贸n del Experimento

* Se configur贸 el experimento en MLflow usando `mlflow.set_experiment("QSAR_Biodegradation_Experiment")`.

### Paso 4: Modelo 1 - Regresi贸n Log铆stica (Registro Manual)

* Se entren贸 un modelo `LogisticRegression` de Scikit-learn.
* Se utiliz贸 **registro manual** para guardar la informaci贸n:
  * `mlflow.log_params()` para guardar hiperpar谩metros (ej. `C`, `solver`).
  * `mlflow.log_metrics()` para guardar m茅tricas de evaluaci贸n (ej. `accuracy`, `f1_score`).
  * `mlflow.log_artifact()` para guardar una Matriz de Confusi贸n como imagen.
  * `mlflow.log_text()` para guardar una descripci贸n.

### Paso 5: Modelo 2 - Red Neuronal (Autologging)

* Se construy贸 una Red Neuronal simple con TensorFlow/Keras.
* Se activ贸 el **autologging** con `mlflow.tensorflow.autolog()`.
* MLflow registr贸 autom谩ticamente todos los par谩metros, m茅tricas por 茅poca (ej. `val_loss`, `val_accuracy`) y el modelo final sin c贸digo adicional.

### Paso 6: Comparaci贸n de Modelos

* Se utiliz贸 la **interfaz de MLflow** (`http://127.0.0.1:5000`) para seleccionar y comparar los dos  *runs* .
* Se analizaron los gr谩ficos de Coordenadas Paralelas y la tabla de m茅tricas para determinar qu茅 modelo ten铆a mejor rendimiento (`f1_score` vs `val_accuracy`).

### Paso 7: Interpretaci贸n con Ollama

* Se utiliz贸 un LLM local (Ollama con `tinyllama`) para analizar los resultados.
* Se le hicieron preguntas como "驴Qu茅 significa un F1-score de 0.89?" y "驴Por qu茅 la NN tendr铆a un F1 m谩s bajo pero un accuracy m谩s alto?".
* La conversaci贸n se guard贸 en `interpretacion_ollama.txt` y se subi贸 a MLflow como un artefacto con `mlflow.log_artifact()`.

### Paso 8: Runs Anidados y Autologging Combinado

* Se activ贸 el autologging general con `mlflow.autolog()`.
* **Anidamiento (Nested Runs):** Se demostr贸 c贸mo agrupar experimentos, creando un "Run Padre" (`LR_Hyperparameter_Search`) que conten铆a m煤ltiples "Runs Hijos" (cada prueba de un valor `C` diferente).
* **Combinado:** Se demostr贸 que `mlflow.autolog()` captur贸 tanto el `fit` de Scikit-learn (en el run anidado) como el `fit` de TensorFlow (en un run separado), probando su capacidad para manejar m煤ltiples frameworks.


##  Gu铆a de Instalaci贸n de Ollama (macOS)

### A. Si NO tienes Ollama instalado:

1. **Descargar:** Ve al sitio web oficial: `https://ollama.com/`
2. **Instalar:** Haz clic en "Download for macOS". Se descargar谩 un archivo `.zip`. Descompr铆melo y ejecuta la aplicaci贸n "Ollama".
3. **Mover a Aplicaciones:** Arrastra el 铆cono de Ollama a tu carpeta de Aplicaciones.
4. **Verificar:** Abre tu Terminal. Ollama se ejecuta como un servicio en segundo plano.
5. **Descargar un Modelo:** Para este taller, `tinyllama` es ligero y suficiente (ya que `llama2` puede requerir m谩s RAM de la disponible).
   **Bash**

   ```
   ollama pull tinyllama
   ```
6. **Ejecutar:** Una vez descargado, inicia el chat:
   **Bash**

   ```
   ollama run tinyllama
   ```
7. 隆Listo! Ya puedes chatear con el modelo. Escribe `/bye` para salir.

### B. Si YA tienes Ollama instalado:

1. **Abrir Terminal:** Abre tu terminal.
2. **Verificar Modelos:** Revisa qu茅 modelos tienes descargados localmente.
   **Bash**

   ```
   ollama list
   ```
3. **Descargar Modelo (si es necesario):** Si no ves `tinyllama:latest` (o el modelo que deseas) en la lista, desc谩rgalo:
   **Bash**

   ```
   ollama pull tinyllama
   ```
4. **Ejecutar:** Inicia el chat con el modelo que desees:
   **Bash**

   ```
   ollama run tinyllama
   ```


##  Estructura del Proyecto

```
.
 MLFlowTracking/	       # (Entorno virtual - Ignorado)
 mlruns/		       # (Datos de MLflow - Ignorado)
 ScreenshotsMLFlow/         # (Capturas de pantalla)
 Informe.docx.              # (Informe breve del proyecto)
 interpretacion_ollama.txt  # (Chat con tinyllama)
 mlflowtracking.ipynb       # (Notebook con todo el c贸digo)
 qsar-biodeg.csv	       # (Dataset usado)
 requirements.txt           # (Dependencias utilizadas)
 .gitignore
```
